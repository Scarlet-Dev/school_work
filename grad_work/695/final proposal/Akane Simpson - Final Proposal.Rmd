---
title             : "Internet Culture â€“ Incel Language Detection within in-groups on the internet"
shorttitle        : "Incel Language Detection"

author: 
  - name          : "Akane Simpson"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "326 Market St, Harrisburg, PA 17101"
    email         : "asimpson@my.harrisburgu.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"

affiliation:
  - id            : "1"
    institution   : "Harrisburg University of Science & Technology"

authornote: 
  
keywords          : "keywords"
wordcount         : "X"


floatsintext      : no
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

header-includes:
  - |
    \makeatletter
    \renewcommand{\paragraph}{@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip @plus 0.2ex @minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{@startsection{subparagraph}{5}{1em}%
      {0\baselineskip @plus 0.2ex @minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output            : papaja::apa6_pdf
bibliography: r-references.bib
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

There is a growing threat in the Western world. Vulnerable men and women are being radicalized online through long-term exposure and interaction with the involuntary celibate. The Involuntary Celibate or incel is an internet subculture that has gained notoriety through recent mass violence attacks. This subculture has been studied and has revealed characteristics unique to the group while bearing some similarities to other internet subcultures and possible real-world terrorists. At the same time, the incel subgroup does not operate the same way as other groups, such as the alt-right, men's rights activists and other online extremist groups. In the next section, we explore some current and past work completed by previous researchers. These researchers have documented several aspects of inceldom and understand how one becomes an incel, the community surrounding it, the actions performed by members of the group, and finally, performing qualitative and quantitative studies on the language used by incels in their online communities.

# Literature Review

## Incel Life and Perspective

The original definition, an incel is someone who has had limited or no sexual interaction with the opposite or same gender for an extended period [@donnelly2001involuntary]. @donnelly2001involuntary involuntary studied who are incels by identifying critical aspects of their lives through interviews with participants ranging from young and single to older and married couples. @donnelly2001involuntary identified a common theme between participants, where participants have endured extended periods of no intimate contact with a mate. They continue by identifying another aspect of these participants where they had delayed sexual and social development in their formative teen years. @donnelly2001involuntary analysis is essential here as it establishes possible some critical features of inceldom. The interviews documented here show that inceldom does not necessarily occur for the young and single but also someone in a long-term relationship.

The couple in this study were married for years, yet, one of the spouses has considered themselves an incel. Does this mean the original definition of incel, although accurate, does not fully explain the often violent and vitriolic actions and speech? Then, what makes an incel an incel?

In a study by @maxwell2020short, the aim was to study the shared experiences, sentiments, and expressions of those who self-identify as incel [-@maxwell2020short pp. 1856]. The results from the research showed that self-identified incels are isolated. Incel's isolation can be a reaction to social and romantic rejection. The rejection causes a reinforcement of negative thought patterns. Eventually, more and more rejection will follow until the rejectee will soon dehumanize the rejecter, women, as a form of vengeance [-@maxwell2020short pp. 1872].

@maxwell2020short study of incel sentiments and experiences, combined with the definition, shows a more accurate idea of an incel.Nevertheless, something is missing. Would sexual rejection be the only factor in turning someone into an incel? People are rejected, daily, but do not necessarily hold a grudge for every rejection. Many would move on from a simple rejection. This rejection may not be the case for incels, as reviewed in the following paper. @stijelja2021psychosocial reviewed, collected, and disserted the psychological variables related to the incel identity and created a psychological profile of what an incel identity entails. Their profile shows that "incels share several characteristics" as "virgins and adults experiencing late sexual onset" [-@stijelja2021psychosocial]. Additionally, the author notices a detail on a particular incel discussion board. Many topics related to mental health received sizable attention, while their discussions aligned with hate speech did not receive the same amount. This focus on mental health could mean that incels are mentally suffering from their lack of sexual contact and venting out their frustrations in their sexual advances met with failure. Another article compiled several interviews with self-identified incels; their experiences generate themes that illustrate their experiences [@daly2022think]. From the results, we see incels are diverse in thought and have levels for each member that divide into the individual, cultural, and societal factors that would drive them into the online community. @daly2022think review should take into consideration that these factors do not operate individually. The rejection an individual receives from another can then lead to rejection from a society built on culture, which will lead to the rejection of the individual [@okada2016]. Sustained cycles of rejection from possible sexual partners, along with preexisting or developing mental health issues, an incel will see the cultural norms and practices instilled in them growing up will clash with our society's current cultural outlook [@weir2012].

Societal rejection may drive someone away from a progressive society and toward traditional values that reinforce their ideas of society. We see this in research by @lindsay2022swallowing. The research focused on exploring the incel online groups' shared worldview called the "Black Pill." By using their language and cultural materials from their public-facing forums. The "Black Pill" is a community device for a shared sense of alienation, and it will facilitate "stochastic terrorism" [-@lindsay2022swallowing], a way for incels to enact their violent solutions to their perceived hatred of out-groups and the world. The author's conclusion identifies a "shared mythology of victimization."[-@lindsay2022swallowing]. The authors note that these worldviews "do not originate in isolation" and are a part of a systemic structure that exists within our society which often goes unchallenged [-@lindsay2021incel]. The incel ideology is inflammatory, racist, homophobic, and misogynist in nature and is pushed by other users and eventually banished from public spaces. @lindsay2021incel recognizes the difficulty in tracking this group in part to their often private and encrypted online spaces, but asserts the need for further studies in identifying the techniques used in their online culture. The "Black Pill" is a social device that incels use to justify hating society, hating the hegemonic masculinity they subscribe to, and, most importantly, hating women. An analysis of @williams2021wanting proves that assertion true. The study is an exploratory analysis that focuses on the incels' intent to harm others in the pursuit of fulfilling their unmet sexual needs or revenge against those whom they feel have wronged them. The analysis concludes that specific motivations, such as revenge, power, and hate, are directed at women, then society which could ultimately drive them to perform planned violence against their perceived enemies. A significantly radicalized incel could be possessed by the "Black Pill" doctrine and be willing to commit terrorist acts. This ideology can also be benign because although an incel has subscribed to the "Black Pill" doctrine, they do not have to commit to an act.

## Incels and Terrorism

Radicalization is an integral part of joining a niche and often violent groups. With enough steps, an ordinary member can turn violent extremists willing to perform terrorist acts for the good of the group's ideals. Terrorists use radicalization to enamor and convert interested individuals into full members of the ideology/cause. Radicalization occurs through reading and teaching the group's doctrine, beliefs, and goals. An authority figure leads these groups in a group or private setting. This process takes time but will produce a member willing to act and die for the group cause.

@doosje2016 studies this radicalization process step-by-step from (1) sensitivity to group grievances and ideals, (2) becoming a member, and finally, (3) acting for the group. They concluded the study that the direct factors in the radicalization process occur on several levels: the individual, the group, and society (micro, meso, macro). As mentioned by @doosje2016, these direct factors are crucial when examining group radicalization. The radicalization process is essential in understanding how individuals can sometimes unknowingly become enamored by the "truths" these groups present. @o2022exploration opens with their study on how extremism and the internet play a role in radicalizing groups into violence, as seen in the incel subculture. In their conclusion, they recognize the five normative orders within the incel group that are part of the process of radicalizing new users: the sexual market, women are evil, that there is a legitimate ideal of masculinity, male oppression, and finally, violence. The five identified orders are consistent with other extremist and terrorist groups' orders used in indoctrinating and radicalizing new adherents. The most recent incel-related terrorist act is an example of someone radicalized by incel and the "Black Pill" theory. The perpetrator wrote in many of his online posts to inspire the dormant and less involved incels to take action against the system. His statement indicates that other terrorist attacks by incels inspire others to follow in their footsteps. How likely are incels intent on committing violence? We study the following survey of @speckhard2021involuntary to answer this question.

@speckhard2021involuntary collected and analyzed questionnaire data from 312 participants from the largest and most active incel-related forum to answer whether the general incel subculture "represents a threat" to others and society. The analyzed data showed that these online forums were a way for incels to vent and listen to others safely but contrasts incel's distrust of the mental health system. The authors' inference of the data suggests that incel forums could be an effective new medium where mental and psychological help incels directly. An online survey assessed 274 incels on their attitudes, beliefs, intentions, thoughts, and personal history related to trauma and mental illness. The assessment identified that most incels sampled from this study rejected violence as an option (74%). The remaining minority indeed indulge in the idea and intent of violence with some fantasizing graphic situations. The survey further reported that the majority did have a history of trauma (bullying, persecution) and mental illness that affected their prospects in life. The survey did note that most incels are non-violent. The ones that initiate violence tend to be hyper-focused on by the news media, which classify them as terrorists. The authors advocate for more mental support groups to intervene before the violent minority within incels act [see @moskalenko2022incel pp. 2, 20].

The incel group also uses radicalization differently. There is no figurehead to guide incels toward a specific goal. Instead, as individuals, each finds their own goal, but rarely works towards it. In this situation, most incels attempt to improve themselves and cure their celibacy. Other incels, usually those deeper in the "Black Pill" theory and have extended periods of celibacy, will abandon hope for improvement or curing their celibacy. Instead, they use this rejection as a cause for violence [@cottee2020incel; @weir2012]. In the incel community, the willingness to act on violence is in the minority. @moskalenko2022incel works in both the survey and analyzing the factors [@moskalenko2022]. Another difference between ordinary terrorists and incels is the medium they spread their message. The incel medium and process through which incels radicalize the individual is unique as it almost wholly operates online and has no figurehead. The online aspect of the incel ideology is represented online, specifically on social media platforms and online forums. In the next section we explore how incels operate in their online world.

Incels on Social Media: Reddit, YouTube and Other Social Media Websites

The incel subculture, as previously mentioned, was created online with origins going as far back as 1997 [@lindsay2021incel] and has continued to exist online. Incels are well acquainted with the internet and its many spaces to express their thoughts and grievances. However, many internet users ostracized incels' actions and their toxic language. The owners of these social media and content-sharing websites, such as Reddit and YouTube, will find it challenging to curtail incel-related content seen in the following papers by @labbaf2019united and @papadamou2021over.

@labbaf2019united published an article that studied how incels form groups based on a shared rage against the other. In their summary, they note how the internet has changed how groups form and how incels are no exception. @labbaf2019united continue to note that the group creates its echo chamber that centers around a voluntary acceptance of their involuntary celibacy, which includes emotions, communication, beliefs, and values. These echo chambers can take many forms in video and text formats. One study explored YouTube as a growing platform for the incel community, its evolution over the past ten years, and whether "YouTube's recommendation algorithm in disseminating incel-related content on the platform" [@papadamou2021over]. The study results show that YouTube has increased incel activity over the past years, with incel-related videos being recommended more frequently to consistent content viewers. @papadamou2021over concludes that there has been growth in incel-related activity on the video platform in terms of published incel videos and the subsequent comments and suggests that users are "gravitating around the community" at an increasing rate. Based on @papadamou2021over and @labbaf2019united work, the most straightforward option to stop the spread of incel content is banning these groups whenever they appear on these major social media platforms. However, banning or limiting the incel content access is not the best action when trying to fight against an online group such as incels. Incels will move platforms and continue to produce content privately, away from discerning eyes [@gillett2022incels]. Other times, the same system that the website uses to curate content has amplified incel content [@papadamou2021over]. We will highlight in-depth studies on how incel content is structured and why it is troublesome to moderate on these social media sites.

@heritage2020incels seeks to understand that incels "use language to construct ideologies around gender and sexuality" while identifying how community members perceive social actors. The authors identified this process through normativity, a step where incels would identify themselves within the group as usual or within a normal range. The author continues where this in-group normativity contrasts how incels also see themselves within society as non-normative. @heritage2020incels concluded by explaining that incels can view certain men and women outside their group as social actors. @heritage2020incels continue further in their explanation of the social actors in incel's non-normative view of these specific men who conform well to society as the desired masculinity and, in turn, see themselves as less desirable in society due to this deficient conformity. The female actors do not get this treatment from incels. The authors note that the sexist language used on these forums shows frustration in incels at women and general society. They further assert that incels try to use this language to position themselves to some men as inferior in the normative society.

@gillett2022incels states, "large-scale content moderation is not the best way for major platforms." Weak content moderation is seen with moderators of these incel subreddits who did not moderate the content posted in their group and actively gate-kept outsiders from accessing and refuting their wild and often toxic claims and "turning inwards." @gillett2022incels writes, "the problem with incels is incels; the group cannot be separated from the toxic ideology that forms their shared identity." [-@gillett2022incels pp. 18]. By "prohibiting overt criticism" and suggesting self-introspection on why they are having difficulties forming a sexual relationship, they legitimize their claim of victimhood and blame others outside their community. Eventually, Reddit soon banned the subreddit and most subsequent new groups related to incels from the site that did not obey the community rules. Nevertheless, the authors warn that banning these groups from public-facing sites will further push incels deeper into more private and obscure sites [-@gillett2022incels pp. 18]. @gillett2022incels correctly asserts that banning incel groups on social media would be detrimental. Incel groups that have formed online overlap in hobbies and specific skills and developed ways to circumvent content moderation. Some of those technical skills that older incels have learned computer programming and website development. Incels use these technical skills to circumvent moderation by toeing the line of moderated content or moving content offsite [-@gillett2022incels]. In addition, incels with high enough technical skills could create their private platforms and restrict access to only incels, thus continuing the echo chamber dynamic [@labbaf2019united]. The best course of action for understanding and documenting the incel language is to monitor or limit access to these subgroups [@gillett2022incels].

From this section, we better understand incel content and how some social media platforms restrict or accelerate the spread of this content [@gillett2022incels; @labbaf2019united]. Studies by @heritage2020incels and @papadamou2021over focused on the language and content of incels incel communities. Moderating harmful content like this is complex and requires cooperation on both sides. Passive monitoring of social media posts is becoming popular as machine learning (supervised and unsupervised learning), and artificial intelligence (AI) advances. An example is Twitter using AI to review content on their websites and flag them as misinformation during the height (2020 - 2021) of the COVID-19 pandemic. We can apply the same techniques in tracking, flagging, and monitoring comments and users. The goal is to further develop research in the incel language and its unique lexicon these online denizens communicate.

## The Incel Language and Lexicon on Reddit

Reddit is a popular social media and content-sharing website that was a host of the first instances of incel-related communities on a high-traffic platform. In the following studies and surveys, we explore the language and lexicon development of incels using several machine-learning techniques to analyze, classify and document the key language features of incels.

In @jaki2019online, the discourse on a popular incel online forum was analyzed and illuminated the incels' affinity to ideas of violent extremism. In summary, the researchers demonstrated identifying an online subculture by its language. They found that the forum used various slang, a focus on biological determinism (physical appearance), hate speech, misogyny, homophobia, and comments ranging from violent/sexual fantasies to incitement of violence against the out-group [@jaki2019online]. However, the author recognizes that some conversations were not in earnest and, instead, a tactic used to self-enhance themselves. @jaki2019online analysis is a crucial step in formulating a process of analyzing online text that can identify someone as a group member. Another study with similar aims unpacks the ambiguous humor of incel content which often masks the underlying toxic content of the media by identifying a lexicon within the media [@gothard2021exploring]. The results show an identifiable lexicon within incel media by combining bigrams and trigrams of general terms used by incels into a glossary. The derived lexicon was identifiable compared to other Reddit groups' lexicons [@gothard2021exploring].

Both @jaki2019online and @gothard2021exploring show that identifying group members are relatively straightforward by using dictionaries. Dictionaries are premade word or phrase banks that assist in text analysis. Known subject matters use preexisting dictionaries. An unknown subject matter could use a dictionary compiled from frequent words and phrases used by group members. Dictionaries are a good reference point and ideal during text analysis and a necessity for any quantitative study. Dictionaries for text analysis studies vary in subject matter, but one study by @van2021grievance established a "Grievance Dictionary." The "Grievance Dictionary" measures, identifies and catalogs psychological and social concepts and any threats of violence and abuse. The authors successfully created this resource that helps other researchers study grievance-fueled language and detect the difference between violent and non-violent texts. This dictionary has many applications applied when performing text analysis on extremist groups.

In @axelsson2021languages, the study investigates how incelhood and incel culture in these online communities help to represent and construct language. In turn, incelhood and culture are represented and constructed by their language. The results show that through interactions on these online forums, incels have not only created their language but also "sociolect" and discourse patterns [@axelsson2021languages]. This result means that incels have evolved further from just shared behaviors, beliefs, and specific cultural elements within the group [@axelsson2021languages].

In @costello2022levels, we see the study's focus more on the mental well-being of incels. From the completion of the study, they identified several key aspects of the mental state of incels. The study asserts that incels have a worse mental state than the average internet user. Their mental state comes with many other issues, alongside mental illness and a darker outlook on life. The issues include loneliness, a disposition for interpersonal victimhood, and sociosexuality. The authors close on a new growing problem where groups will become harder to reach for mental health intervention. The study's results could add another layer to identifying incels online through their known talking points, a curated dictionary, and now possible references to mental health using semantics analysis. Next, we need to identify some machine-learning techniques, we may need to apply to our study.

A natural language processing (NLP) study by @Torregrosa2021 collected and analyzed content focused on extremist thought and language. In @Torregrosa2021 analysis, they answered several questions, such as (1) what extremism is and the related discourse, (2) "the NLP techniques used to analyze a text", (3) applications of those techniques, and (4) "software tools and extremism datasets." The study included using specific NLP techniques and its data processing requirements of text preprocessing and feature generation that will apply to this study [-@Torregrosa2021 pp. 3]. Continuing with text analysis studies, @pelzer2021toxic sampled the online text of incels on three digital platforms. They attempted to measure the amount of hate speech or 'hate levels' in incels' comments and identify the target of this speech. They concluded that most hate speech targets women and men whom they envy. The levels of hate vary from forum to forum ranging from misogyny and racism, but most of the hate was self-hate. Interestingly, the authors could not measure 'hate levels' in their forums but did note that it would be interesting to research toxic language development in new users.

@sang2020analyzing studied the extent of hate speech features in comments posted by incels while exploring the post's title as a possible tool in understanding the poster's attitude towards other original incel media (screenshots). After processing the data using semantics analysis, the authors' results show frequent signs of negative emotions in an incel texts---a semantic link "between word usage in incel-related" speech and the summary of a title" [-@sang2020analyzing]. Finally, a quantitative article by @schmitz2022quantifying studies whether the user's speech will becomes hateful outside of that subreddit after a user joins a hateful subreddit. The data summary shows that consistent exposure to incel content impacted users and increased hate speech. Three categories emerged in the users' new speech: racism, misogyny, and fat-shaming. @schmitz2022quantifying research aim is similar to this studies aim and should be considered an extension of their work.

Several reviewed studies understand the incel ideology, and language has several factors that can entice like-minded users to ingest incel content. The incel content and culture would seem attractive to many lonely men with difficulties forming romantic connections as they accept a fatalist approach to life [@donnelly2001involuntary]. However, studies by @schmitz2022quantifying and @pelzer2021toxic established possible research questions that have merit in diving further. Can one measure the radicalization of a user on a subreddit after consistent interaction with incel content [@moskalenko2022incel]? Also, is it possible to calculate a cumulative radicalization value similar to @schmitz2022quantifying that takes into account the previous lexicon and language studies in @hajarian2019snefl and @van2021grievance? Based on previous work on this topic, we can develop an algorithm that pinpoints the starting point of radicalization using a cumulative score-based system that measures word usage, semantics, PAC, and the intended targets [@bridgelall2022application; @moskalenko2022; @Torregrosa2021]. Therefore, this study proposes that exposure to common incel language and sentiments within Reddit groups will increase users' use of similar comments and posts in their online interactions, thus leading to radicalization.

In this section we will develop a quantitative analysis user comments and posts made on the social media platform, Reddit, and perform a semantics and sentimental analysis on users comments posts using natural language processing techniques, model generation and time period observation. This research should be considered a casual comparative research where we study radicalization through observing a change in user commenting behavior within a period of time (from first post to latest) while weighed against other factors. This study will be performed exclusively online during October 2022 til June 2023.

## Participants

In the demography of incels compiled by @moskalenko2022, most of the participants are white males with most having only a high school education. These incels have previously been bullied and suffer some form of mental health illness. Many of these incels are regular users of social media and often post problematic content to these platforms. Although not stated by @moskalenko2022 we will assume that most of these participants are between 18 to 35 years old although we have should some outliers during the collection process. Additionally, we will allow other races, gender We assert that incels will indulge in computer specific hobbies or interest due to their interactions mostly online [@incelwikihobby2021]. These hobbies and interests would include gaming, technology and gaming news and popular culture. These interests will help us when searching for participants on the social media platform, Reddit.

Although we have a general characteristics of the possible participants the data that we will retrieve from Reddit is mostly anonymous. Instead we will use the hobbies of incels as a starting point in our search. Therefore, our search will mine user data on popular video game and computer related subreddits. The search results will then be extracted for user information from searched subreddits and focused on key features such as username, posts, comments and subreddits these participants interact with. The users are mostly anonymous with only their username being available. The study will maintain this anonymity during the analysis and manipulation of the data by assigning randomly generated short hashes as identifiers.

## Procedure

### The Reddit API

The study will first identify, measure and observe interactions by users on Reddit. Reddit has a application programming interface (API) that developers our scientist can use to query the platform for data. Anyone can use this API by creating an account and gaining an access token that identifies your queries to the API. The Reddit API allows several actions but in this study we will focus on the ability to filter, search and sort for subreddits. The API also allows searched for specific users using their screen names and and advanced queries to learn more about a users previous subreddit submissions.

The Reddit API allows us to retrieve data from different subreddits and provide deeper incites into communities of interest. We shall retrieve a maximum of 200 unique comments and assess them for incel content. If the comment or posts does contain incel themes, topics or language we shall select that user to perform an deep dive through their users profile. The secondary search will mine available posts made by the selected participants. From there we will preform out analysis to establish a timeline from the first comment made by the selected user till the most recent comment. It should be expected that users who have an extended post history are the most desired and are more legitimate

### Extraction Tools

The Reddit API tools will work will with our quantitative study, but, we will use a programming tool called PRAW (Python Reddit API Wrapper) to provide a development algorithms for repeated experiments. PRAW is a wrapper tool that wraps the functions in the API into a code friendly format. Using @praw along with data science tool-set like @scikit-learn , text and sentiment analysis from 'NLTK' and visualizing the results using @seaborn.

### Limitations

Reddit catalog data that its users posts into subreddits, some are public facing and allow other users to follow. Other times, a user may post their content directly to their user pages subreddit. Users also create private subreddits and require an invitation by other group members or the pages moderator to have access. These different access methods present some challenges to reading data on a user or subreddit.

Searching subreddits for possible incel activity will take some time. This requires several rounds of searches using the API wrapper, sampling subreddit posts and verifying that the selected user has a long enough history on the website and post often enough to generate a timeline. Additionally, this could also reveal users that have similar perspectives as incels but do not follow the same worldview. These users cold be studied in a different paper.

## Measures

There are several measures that will be required in this study. Some measures can be found by extracting the desired feature from the two data sources. Other measures will need to be calculated by using external resources and previous work done by @Torregrosa2021, @schmitz2022quantifying, @doosje2016, @gothard2021exploring in creating criteria that addresses critical features that will be examined in this study. This criteria will be used to measure several elements in common incel language and attempt to identify words, phrases and themes that may be present within these comments and text.

### Measuring 'Hate Levels'

'Hate levels' as described by @pelzer2021toxic are a proposed measured value of hate that may be found through text analysis of extremist content. @pelzer2021toxic We will combine the sentiment value of the user's comments or posts, weight the subreddit the comment or posts were made in (if the subreddit has ties to incel content or topics

### Measuring Sentiment

Sentiment analysis is the identification and classification of opinions express in a binary value of either positive, negative values. By assessing the words used in text we can assign a 1 to -1 range based on the word meaning. An example of this is in @axelsson2021languages where they describe the language of incels as toxic. We will use those words processed by out data munging and compare them to a dictionary similar to @van2021grievance. We would expect a binary value from this to signify whether the Reddit comment/post contains the same words or phrases found in the dictionary -@van2021grievance.

### Measuring Time

In this measure we will use the data provided to outline a timeline of a user from their first encounter of incel-related content till their most recent encounter. We hope to find several users that fit this measure to create an average and median time variable it takes a user to become fully radicalized by the incel idea [@schmitz2022quantifying].

This time measure will be validated based on the delta from the start of observation till the most recent post. We will further assess the time measure by correlating it with our sentiment and 'hate levels' measures. If there is a strong positive correlation between these three measures we can assume that these are good classification features.

## Analysis

Analyzing the data will also take up a considerable amount of time. Our intended process will involve model training and testing. The model will be built using multiple model building techniques to create a classification model that will perform two tasks, predict if a selected comment is incel inspired and calculate the cumulative 'hate levels' from key data features. Before we begin the analysis we must ensure the data integrity. We shall review the data and perform the following steps:

1.  Review the raw data and select features that are related to our research goals.

2.  We shall clean the data by removing incomplete cases, check and remove outliers in the data and normalize (scale, center, normalize) the continuous variables in the dataset.

3.  We shall create three training/validation sets manipulated using different levels of feature manipulation: only normalization, feature selection using correlation and feature engineering using Principal Component Analysis (PCA). The training data will be cross validated before model training can begin.

4.  Finally, we shall create models using the training sets and compare the model results.

5.  We select the model that has the overall results and provide it with more data to create further predictions from additional user data.

Completing the appropriate procedures in cleaning, processing and extracting relevant features for the study is an important step of the analysis. If the data contains issues or misrepresentation then the subsequent model and their results will be incorrect. The steps above will create a cleaned dataset that will not affect future model development. At the end our analysis should answer our model expectations:

-   The classification model should accurately predict with over a 80% accuracy if a comment was made by an incel

-   The data will have features that correlate with the sentiment score and the 'hate levels' score from the data.

-   The model, when given a time range is able to sample comments/posts within the range and attempt to predict the 'hate levels' and sentiment value of the sampled comments/posts.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
